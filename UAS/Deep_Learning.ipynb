{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Basic Tensor**"
      ],
      "metadata": {
        "id": "Bs5Wrgo39Qej"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOpNLDKL6wy0",
        "outputId": "ca15a7fc-f96e-43d5-a5bc-2bd411fd428e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.2609e-33])\n",
            "tensor([6.7750e-35, 4.5611e-41, 1.2459e-33])\n",
            "tensor([[6.7750e-35, 4.5611e-41, 1.2747e-33],\n",
            "        [0.0000e+00, 7.2975e-22, 4.5609e-41]])\n",
            "tensor([[[ 1.1207e-33,  0.0000e+00,  1.6672e-33],\n",
            "         [ 0.0000e+00,  4.4842e-44,  0.0000e+00]],\n",
            "\n",
            "        [[ 8.9683e-44,  0.0000e+00,  1.2207e-33],\n",
            "         [ 0.0000e+00, -1.9602e-30,  4.5609e-41]]])\n",
            "tensor([[0.5760, 0.4298, 0.4495],\n",
            "        [0.9114, 0.0264, 0.9283],\n",
            "        [0.0051, 0.4386, 0.9567],\n",
            "        [0.8656, 0.2040, 0.6252],\n",
            "        [0.2075, 0.3548, 0.7147]])\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "torch.Size([5, 3])\n",
            "torch.float32\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]], dtype=torch.float16)\n",
            "torch.float16\n",
            "torch.Size([2])\n",
            "tensor([[0.4311, 0.1976, 0.1688],\n",
            "        [0.8859, 0.2600, 0.4443],\n",
            "        [0.2759, 0.8885, 0.1547],\n",
            "        [0.4829, 0.6335, 0.4783],\n",
            "        [0.4665, 0.4644, 0.9853]])\n",
            "tensor([0.4311, 0.8859, 0.2759, 0.4829, 0.4665])\n",
            "tensor([0.8859, 0.2600, 0.4443])\n",
            "tensor(0.2600)\n",
            "0.2600465416908264\n",
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n",
            "tensor([1., 1., 1., 1., 1.])\n",
            "[1. 1. 1. 1. 1.]\n",
            "<class 'numpy.ndarray'>\n",
            "tensor([2., 2., 2., 2., 2.])\n",
            "[2. 2. 2. 2. 2.]\n",
            "[1. 1. 1. 1. 1.]\n",
            "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Everything in pytorch is based on Tensor operations.\n",
        "# A tensor can have different dimensions\n",
        "# so it can be 1d, 2d, or even 3d and higher\n",
        "\n",
        "# scalar, vector, matrix, tensor\n",
        "\n",
        "# torch.empty(size): uninitiallized\n",
        "x = torch.empty(1) # scalar\n",
        "print(x)\n",
        "x = torch.empty(3) # vector, 1D\n",
        "print(x)\n",
        "x = torch.empty(2,3) # matrix, 2D\n",
        "print(x)\n",
        "x = torch.empty(2,2,3) # tensor, 3 dimensions\n",
        "#x = torch.empty(2,2,2,3) # tensor, 4 dimensions\n",
        "print(x)\n",
        "\n",
        "# torch.rand(size): random numbers [0, 1]\n",
        "x = torch.rand(5, 3)\n",
        "print(x)\n",
        "\n",
        "# torch.zeros(size), fill with 0\n",
        "# torch.ones(size), fill with 1\n",
        "x = torch.zeros(5, 3)\n",
        "print(x)\n",
        "\n",
        "# check size\n",
        "print(x.size())\n",
        "\n",
        "# check data type\n",
        "print(x.dtype)\n",
        "\n",
        "# specify types, float32 default\n",
        "x = torch.zeros(5, 3, dtype=torch.float16)\n",
        "print(x)\n",
        "\n",
        "# check type\n",
        "print(x.dtype)\n",
        "\n",
        "# construct from data\n",
        "x = torch.tensor([5.5, 3])\n",
        "print(x.size())\n",
        "\n",
        "# requires_grad argument\n",
        "# This will tell pytorch that it will need to calculate the gradients for this tensor\n",
        "# later in your optimization steps\n",
        "# i.e. this is a variable in your model that you want to optimize\n",
        "x = torch.tensor([5.5, 3], requires_grad=True)\n",
        "\n",
        "# Operations\n",
        "y = torch.rand(2, 2)\n",
        "x = torch.rand(2, 2)\n",
        "\n",
        "# elementwise addition\n",
        "z = x + y\n",
        "# torch.add(x,y)\n",
        "\n",
        "# in place addition, everythin with a trailing underscore is an inplace operation\n",
        "# i.e. it will modify the variable\n",
        "# y.add_(x)\n",
        "\n",
        "# substraction\n",
        "z = x - y\n",
        "z = torch.sub(x, y)\n",
        "\n",
        "# multiplication\n",
        "z = x * y\n",
        "z = torch.mul(x,y)\n",
        "\n",
        "# division\n",
        "z = x / y\n",
        "z = torch.div(x,y)\n",
        "\n",
        "# Slicing\n",
        "x = torch.rand(5,3)\n",
        "print(x)\n",
        "print(x[:, 0]) # all rows, column 0\n",
        "print(x[1, :]) # row 1, all columns\n",
        "print(x[1,1]) # element at 1, 1\n",
        "\n",
        "# Get the actual value if only 1 element in your tensor\n",
        "print(x[1,1].item())\n",
        "\n",
        "# Reshape with torch.view()\n",
        "x = torch.randn(4, 4)\n",
        "y = x.view(16)\n",
        "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
        "# if -1 it pytorch will automatically determine the necessary size\n",
        "print(x.size(), y.size(), z.size())\n",
        "\n",
        "# Numpy\n",
        "# Converting a Torch Tensor to a NumPy array and vice versa is very easy\n",
        "a = torch.ones(5)\n",
        "print(a)\n",
        "\n",
        "# torch to numpy with .numpy()\n",
        "b = a.numpy()\n",
        "print(b)\n",
        "print(type(b))\n",
        "\n",
        "# Carful: If the Tensor is on the CPU (not the GPU),\n",
        "# both objects will share the same memory location, so changing one\n",
        "# will also change the other\n",
        "a.add_(1)\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "# numpy to torch with .from_numpy(x)\n",
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "# again be careful when modifying\n",
        "a += 1\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "# by default all tensors are created on the CPU,\n",
        "# but you can also move them to the GPU (only if it's available )\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    # z = z.numpy() # not possible because numpy cannot handle GPU tenors\n",
        "    # move to CPU again\n",
        "    z.to(\"cpu\")       # ``.to`` can also change dtype together!\n",
        "    # z = z.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Autograd**"
      ],
      "metadata": {
        "id": "uOg9A-UG9xyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "# The autograd package provides automatic differentiation\n",
        "# for all operations on Tensors\n",
        "\n",
        "# requires_grad = True -> tracks all operations on the tensor.\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "y = x + 2\n",
        "\n",
        "# y was created as a result of an operation, so it has a grad_fn attribute.\n",
        "# grad_fn: references a Function that has created the Tensor\n",
        "print(x) # created by the user -> grad_fn is None\n",
        "print(y)\n",
        "print(y.grad_fn)\n",
        "\n",
        "# Do more operations on y\n",
        "z = y * y * 3\n",
        "print(z)\n",
        "z = z.mean()\n",
        "print(z)\n",
        "\n",
        "# Let's compute the gradients with backpropagation\n",
        "# When we finish our computation we can call .backward() and have all the gradients computed automatically.\n",
        "# The gradient for this tensor will be accumulated into .grad attribute.\n",
        "# It is the partial derivate of the function w.r.t. the tensor\n",
        "\n",
        "z.backward()\n",
        "print(x.grad) # dz/dx\n",
        "\n",
        "# Generally speaking, torch.autograd is an engine for computing vector-Jacobian product\n",
        "# It computes partial derivates while applying the chain rule\n",
        "\n",
        "# -------------\n",
        "# Model with non-scalar output:\n",
        "# If a Tensor is non-scalar (more than 1 elements), we need to specify arguments for backward()\n",
        "# specify a gradient argument that is a tensor of matching shape.\n",
        "# needed for vector-Jacobian product\n",
        "\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "for _ in range(10):\n",
        "    y = y * 2\n",
        "\n",
        "print(y)\n",
        "print(y.shape)\n",
        "\n",
        "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float32)\n",
        "y.backward(v)\n",
        "print(x.grad)\n",
        "\n",
        "# -------------\n",
        "# Stop a tensor from tracking history:\n",
        "# For example during our training loop when we want to update our weights\n",
        "# then this update operation should not be part of the gradient computation\n",
        "# - x.requires_grad_(False)\n",
        "# - x.detach()\n",
        "# - wrap in 'with torch.no_grad():'\n",
        "\n",
        "# .requires_grad_(...) changes an existing flag in-place.\n",
        "a = torch.randn(2, 2)\n",
        "print(a.requires_grad)\n",
        "b = ((a * 3) / (a - 1))\n",
        "print(b.grad_fn)\n",
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n",
        "b = (a * a).sum()\n",
        "print(b.grad_fn)\n",
        "\n",
        "# .detach(): get a new Tensor with the same content but no gradient computation:\n",
        "a = torch.randn(2, 2, requires_grad=True)\n",
        "print(a.requires_grad)\n",
        "b = a.detach()\n",
        "print(b.requires_grad)\n",
        "\n",
        "# wrap in 'with torch.no_grad():'\n",
        "a = torch.randn(2, 2, requires_grad=True)\n",
        "print(a.requires_grad)\n",
        "with torch.no_grad():\n",
        "    print((x ** 2).requires_grad)\n",
        "\n",
        "# -------------\n",
        "# backward() accumulates the gradient for this tensor into .grad attribute.\n",
        "# !!! We need to be careful during optimization !!!\n",
        "# Use .zero_() to empty the gradients before a new optimization step!\n",
        "weights = torch.ones(4, requires_grad=True)\n",
        "\n",
        "for epoch in range(3):\n",
        "    # just a dummy example\n",
        "    model_output = (weights*3).sum()\n",
        "    model_output.backward()\n",
        "\n",
        "    print(weights.grad)\n",
        "\n",
        "    # optimize model, i.e. adjust weights...\n",
        "    with torch.no_grad():\n",
        "        weights -= 0.1 * weights.grad\n",
        "\n",
        "    # this is important! It affects the final weights & output\n",
        "    weights.grad.zero_()\n",
        "\n",
        "print(weights)\n",
        "print(model_output)\n",
        "\n",
        "# Optimizer has zero_grad() method\n",
        "# optimizer = torch.optim.SGD([weights], lr=0.1)\n",
        "# During training:\n",
        "# optimizer.step()\n",
        "# optimizer.zero_grad()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdBz8n3x8O5x",
        "outputId": "2ed9177a-bb40-411a-8968-8f239a78f48c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.3403,  1.9280,  0.5184], requires_grad=True)\n",
            "tensor([0.6597, 3.9280, 2.5184], grad_fn=<AddBackward0>)\n",
            "<AddBackward0 object at 0x7f241c587910>\n",
            "tensor([ 1.3055, 46.2881, 19.0275], grad_fn=<MulBackward0>)\n",
            "tensor(22.2070, grad_fn=<MeanBackward0>)\n",
            "tensor([1.3193, 7.8560, 5.0369])\n",
            "tensor([ 743.8804,  939.6523, 1588.8334], grad_fn=<MulBackward0>)\n",
            "torch.Size([3])\n",
            "tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n",
            "False\n",
            "None\n",
            "True\n",
            "<SumBackward0 object at 0x7f241c587910>\n",
            "True\n",
            "False\n",
            "True\n",
            "False\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([0.1000, 0.1000, 0.1000, 0.1000], requires_grad=True)\n",
            "tensor(4.8000, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BackPropagation**"
      ],
      "metadata": {
        "id": "eny6g1Hc-D7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "\n",
        "# This is the parameter we want to optimize -> requires_grad=True\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# forward pass to compute loss\n",
        "y_predicted = w * x\n",
        "loss = (y_predicted - y)**2\n",
        "print(loss)\n",
        "\n",
        "# backward pass to compute gradient dLoss/dw\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "\n",
        "# update weights\n",
        "# next forward and backward pass...\n",
        "\n",
        "# continue optimizing:\n",
        "# update weights, this operation should not be part of the computational graph\n",
        "with torch.no_grad():\n",
        "    w -= 0.01 * w.grad\n",
        "# don't forget to zero the gradients\n",
        "w.grad.zero_()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAdLffvB8h0S",
        "outputId": "f3485113-ea43-4488-f0cc-6ebc37aa5839"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n",
            "tensor(-2.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradientdescent**"
      ],
      "metadata": {
        "id": "IVIjdiA7-ISf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Compute every step manually\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x\n",
        "\n",
        "# here : f = 2 * x\n",
        "X = np.array([1, 2, 3, 4], dtype=np.float32)\n",
        "Y = np.array([2, 4, 6, 8], dtype=np.float32)\n",
        "\n",
        "w = 0.0\n",
        "\n",
        "# model output\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "# loss = MSE\n",
        "def loss(y, y_pred):\n",
        "    return ((y_pred - y)**2).mean()\n",
        "\n",
        "# J = MSE = 1/N * (w*x - y)**2\n",
        "# dJ/dw = 1/N * 2x(w*x - y)\n",
        "def gradient(x, y, y_pred):\n",
        "    return np.mean(2*x*(y_pred - y))\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 20\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass\n",
        "    y_pred = forward(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_pred)\n",
        "\n",
        "    # calculate gradients\n",
        "    dw = gradient(X, Y, y_pred)\n",
        "\n",
        "    # update weights\n",
        "    w -= learning_rate * dw\n",
        "\n",
        "    if epoch % 2 == 0:\n",
        "        print(f'epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5):.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8A-didA-HP1",
        "outputId": "aa4c0c72-139e-4fe4-dec1-387b1de4ea42"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch 1: w = 0.300, loss = 30.00000000\n",
            "epoch 3: w = 0.772, loss = 15.66018677\n",
            "epoch 5: w = 1.113, loss = 8.17471600\n",
            "epoch 7: w = 1.359, loss = 4.26725292\n",
            "epoch 9: w = 1.537, loss = 2.22753215\n",
            "epoch 11: w = 1.665, loss = 1.16278565\n",
            "epoch 13: w = 1.758, loss = 0.60698175\n",
            "epoch 15: w = 1.825, loss = 0.31684822\n",
            "epoch 17: w = 1.874, loss = 0.16539653\n",
            "epoch 19: w = 1.909, loss = 0.08633806\n",
            "Prediction after training: f(5) = 9.612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Here we replace the manually computed gradient with autograd\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x\n",
        "\n",
        "# here : f = 2 * x\n",
        "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# model output\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "# loss = MSE\n",
        "def loss(y, y_pred):\n",
        "    return ((y_pred - y)**2).mean()\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5).item():.3f}')\n",
        "\n",
        "# Training\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass\n",
        "    y_pred = forward(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_pred)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    #w.data = w.data - learning_rate * w.grad\n",
        "    with torch.no_grad():\n",
        "        w -= learning_rate * w.grad\n",
        "\n",
        "    # zero the gradients after updating\n",
        "    w.grad.zero_()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f'epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.8f}')\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBzV1Jzp-daF",
        "outputId": "966eb883-c352-4c4a-b202-ef469da451a9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch 1: w = 0.300, loss = 30.00000000\n",
            "epoch 11: w = 1.665, loss = 1.16278565\n",
            "epoch 21: w = 1.934, loss = 0.04506890\n",
            "epoch 31: w = 1.987, loss = 0.00174685\n",
            "epoch 41: w = 1.997, loss = 0.00006770\n",
            "epoch 51: w = 1.999, loss = 0.00000262\n",
            "epoch 61: w = 2.000, loss = 0.00000010\n",
            "epoch 71: w = 2.000, loss = 0.00000000\n",
            "epoch 81: w = 2.000, loss = 0.00000000\n",
            "epoch 91: w = 2.000, loss = 0.00000000\n",
            "Prediction after training: f(5) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**loss and optimize**"
      ],
      "metadata": {
        "id": "7KePQE4k-kI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x\n",
        "\n",
        "# here : f = 2 * x\n",
        "\n",
        "# 0) Training samples\n",
        "X = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
        "Y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
        "\n",
        "# 1) Design Model: Weights to optimize and forward function\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "def forward(x):\n",
        "    return w * x\n",
        "\n",
        "print(f'Prediction before training: f(5) = {forward(5).item():.3f}')\n",
        "\n",
        "# 2) Define loss and optimizer\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "# callable function\n",
        "loss = nn.MSELoss()\n",
        "\n",
        "optimizer = torch.optim.SGD([w], lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass\n",
        "    y_predicted = forward(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_predicted)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero the gradients after updating\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print('epoch ', epoch+1, ': w = ', w, ' loss = ', l)\n",
        "\n",
        "print(f'Prediction after training: f(5) = {forward(5).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gleJVLy9-y1Q",
        "outputId": "69a1e56c-9cdd-45ca-8265-7bf73adf241f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch  1 : w =  tensor(0.3000, requires_grad=True)  loss =  tensor(30., grad_fn=<MseLossBackward0>)\n",
            "epoch  11 : w =  tensor(1.6653, requires_grad=True)  loss =  tensor(1.1628, grad_fn=<MseLossBackward0>)\n",
            "epoch  21 : w =  tensor(1.9341, requires_grad=True)  loss =  tensor(0.0451, grad_fn=<MseLossBackward0>)\n",
            "epoch  31 : w =  tensor(1.9870, requires_grad=True)  loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n",
            "epoch  41 : w =  tensor(1.9974, requires_grad=True)  loss =  tensor(6.7705e-05, grad_fn=<MseLossBackward0>)\n",
            "epoch  51 : w =  tensor(1.9995, requires_grad=True)  loss =  tensor(2.6244e-06, grad_fn=<MseLossBackward0>)\n",
            "epoch  61 : w =  tensor(1.9999, requires_grad=True)  loss =  tensor(1.0176e-07, grad_fn=<MseLossBackward0>)\n",
            "epoch  71 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(3.9742e-09, grad_fn=<MseLossBackward0>)\n",
            "epoch  81 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(1.4670e-10, grad_fn=<MseLossBackward0>)\n",
            "epoch  91 : w =  tensor(2.0000, requires_grad=True)  loss =  tensor(5.0768e-12, grad_fn=<MseLossBackward0>)\n",
            "Prediction after training: f(5) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Linear regression\n",
        "# f = w * x\n",
        "\n",
        "# here : f = 2 * x\n",
        "\n",
        "# 0) Training samples, watch the shape!\n",
        "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(f'#samples: {n_samples}, #features: {n_features}')\n",
        "# 0) create a test sample\n",
        "X_test = torch.tensor([5], dtype=torch.float32)\n",
        "\n",
        "# 1) Design Model, the model has to implement the forward pass!\n",
        "# Here we can use a built-in model from PyTorch\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "# we can call this model with samples X\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "'''\n",
        "class LinearRegression(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(LinearRegression, self).__init__()\n",
        "        # define diferent layers\n",
        "        self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lin(x)\n",
        "\n",
        "model = LinearRegression(input_size, output_size)\n",
        "'''\n",
        "\n",
        "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
        "\n",
        "# 2) Define loss and optimizer\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "for epoch in range(n_iters):\n",
        "    # predict = forward pass with our model\n",
        "    y_predicted = model(X)\n",
        "\n",
        "    # loss\n",
        "    l = loss(Y, y_predicted)\n",
        "\n",
        "    # calculate gradients = backward pass\n",
        "    l.backward()\n",
        "\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero the gradients after updating\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        [w, b] = model.parameters() # unpack parameters\n",
        "        print('epoch ', epoch+1, ': w = ', w[0][0].item(), ' loss = ', l)\n",
        "\n",
        "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y94GyeiN_GWY",
        "outputId": "5eb931f5-42e9-41e0-e158-98c30ee85554"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#samples: 4, #features: 1\n",
            "Prediction before training: f(5) = -4.285\n",
            "epoch  1 : w =  -0.32861682772636414  loss =  tensor(63.8725, grad_fn=<MseLossBackward0>)\n",
            "epoch  11 : w =  1.5055800676345825  loss =  tensor(1.6817, grad_fn=<MseLossBackward0>)\n",
            "epoch  21 : w =  1.8041493892669678  loss =  tensor(0.0710, grad_fn=<MseLossBackward0>)\n",
            "epoch  31 : w =  1.8556098937988281  loss =  tensor(0.0277, grad_fn=<MseLossBackward0>)\n",
            "epoch  41 : w =  1.8672219514846802  loss =  tensor(0.0251, grad_fn=<MseLossBackward0>)\n",
            "epoch  51 : w =  1.8723256587982178  loss =  tensor(0.0236, grad_fn=<MseLossBackward0>)\n",
            "epoch  61 : w =  1.8762872219085693  loss =  tensor(0.0222, grad_fn=<MseLossBackward0>)\n",
            "epoch  71 : w =  1.8799721002578735  loss =  tensor(0.0209, grad_fn=<MseLossBackward0>)\n",
            "epoch  81 : w =  1.883522391319275  loss =  tensor(0.0197, grad_fn=<MseLossBackward0>)\n",
            "epoch  91 : w =  1.886963963508606  loss =  tensor(0.0186, grad_fn=<MseLossBackward0>)\n",
            "Prediction after training: f(5) = 9.773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Regression**"
      ],
      "metadata": {
        "id": "Ytq_XPAF_k0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 0) Prepare data\n",
        "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=4)\n",
        "\n",
        "# cast to float Tensor\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "y = y.view(y.shape[0], 1)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "# 1) Model\n",
        "# Linear model f = wx + b\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "# 2) Loss and optimizer\n",
        "learning_rate = 0.01\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass and loss\n",
        "    y_predicted = model(X)\n",
        "    loss = criterion(y_predicted, y)\n",
        "\n",
        "    # Backward pass and update\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero grad before new step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "# Plot\n",
        "predicted = model(X).detach().numpy()\n",
        "\n",
        "plt.plot(X_numpy, y_numpy, 'ro')\n",
        "plt.plot(X_numpy, predicted, 'b')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "8Rr_BojX_KO5",
        "outputId": "d8469193-6b29-498c-b1bd-26726df631c4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 3994.2788\n",
            "epoch: 20, loss = 2816.3792\n",
            "epoch: 30, loss = 2013.4001\n",
            "epoch: 40, loss = 1465.8892\n",
            "epoch: 50, loss = 1092.4906\n",
            "epoch: 60, loss = 837.7837\n",
            "epoch: 70, loss = 664.0053\n",
            "epoch: 80, loss = 545.4187\n",
            "epoch: 90, loss = 464.4798\n",
            "epoch: 100, loss = 409.2260\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "_XrAd7Bz_tYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 0) Prepare data\n",
        "bc = datasets.load_breast_cancer()\n",
        "X, y = bc.data, bc.target\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "\n",
        "# scale\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "y_train = y_train.view(y_train.shape[0], 1)\n",
        "y_test = y_test.view(y_test.shape[0], 1)\n",
        "\n",
        "# 1) Model\n",
        "# Linear model f = wx + b , sigmoid at the end\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "\n",
        "model = Model(n_features)\n",
        "\n",
        "# 2) Loss and optimizer\n",
        "num_epochs = 100\n",
        "learning_rate = 0.01\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# 3) Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass and loss\n",
        "    y_pred = model(X_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "\n",
        "    # Backward pass and update\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # zero grad before new step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_predicted = model(X_test)\n",
        "    y_predicted_cls = y_predicted.round()\n",
        "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
        "    print(f'accuracy: {acc.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKkNTyIX_xUr",
        "outputId": "2c934a0b-2f15-4582-983d-5f3fac77da58"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 0.4600\n",
            "epoch: 20, loss = 0.3931\n",
            "epoch: 30, loss = 0.3479\n",
            "epoch: 40, loss = 0.3151\n",
            "epoch: 50, loss = 0.2901\n",
            "epoch: 60, loss = 0.2703\n",
            "epoch: 70, loss = 0.2542\n",
            "epoch: 80, loss = 0.2408\n",
            "epoch: 90, loss = 0.2294\n",
            "epoch: 100, loss = 0.2196\n",
            "accuracy: 0.9123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Loader**"
      ],
      "metadata": {
        "id": "kn66bKP7ADbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# gradient computation etc. not efficient for whole data set\n",
        "# -> divide dataset into small batches\n",
        "\n",
        "'''\n",
        "# training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # loop over all batches\n",
        "    for i in range(total_batches):\n",
        "        batch_x, batch_y = ...\n",
        "'''\n",
        "\n",
        "# epoch = one forward and backward pass of ALL training samples\n",
        "# batch_size = number of training samples used in one forward/backward pass\n",
        "# number of iterations = number of passes, each pass (forward+backward) using [batch_size] number of sampes\n",
        "# e.g : 100 samples, batch_size=20 -> 100/20=5 iterations for 1 epoch\n",
        "\n",
        "# --> DataLoader can do the batch computation for us\n",
        "\n",
        "# Implement a custom Dataset:\n",
        "# inherit Dataset\n",
        "# implement __init__ , __getitem__ , and __len__\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "        # Initialize data, download, etc.\n",
        "        # read with numpy or pandas\n",
        "        xy = np.loadtxt('/content/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
        "        self.n_samples = xy.shape[0]\n",
        "\n",
        "        # here the first column is the class label, the rest are the features\n",
        "        self.x_data = torch.from_numpy(xy[:, 1:]) # size [n_samples, n_features]\n",
        "        self.y_data = torch.from_numpy(xy[:, [0]]) # size [n_samples, 1]\n",
        "\n",
        "    # support indexing such that dataset[i] can be used to get i-th sample\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    # we can call len(dataset) to return the size\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "\n",
        "# create dataset\n",
        "dataset = WineDataset()\n",
        "\n",
        "# get first sample and unpack\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(features, labels)\n",
        "\n",
        "# Load whole dataset with DataLoader\n",
        "# shuffle: shuffle data, good for training\n",
        "# num_workers: faster loading with multiple subprocesses\n",
        "# !!! IF YOU GET AN ERROR DURING LOADING, SET num_workers TO 0 !!!\n",
        "train_loader = DataLoader(dataset=dataset,\n",
        "                          batch_size=4,\n",
        "                          shuffle=True,\n",
        "                          num_workers=2)\n",
        "\n",
        "# convert to an iterator and look at one random sample\n",
        "dataiter = iter(train_loader)\n",
        "data = next(dataiter)\n",
        "features, labels = data\n",
        "print(features, labels)\n",
        "\n",
        "# Dummy Training loop\n",
        "num_epochs = 2\n",
        "total_samples = len(dataset)\n",
        "n_iterations = math.ceil(total_samples/4)\n",
        "print(total_samples, n_iterations)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "\n",
        "        # here: 178 samples, batch_size = 4, n_iters=178/4=44.5 -> 45 iterations\n",
        "        # Run your training process\n",
        "        if (i+1) % 5 == 0:\n",
        "            print(f'Epoch: {epoch+1}/{num_epochs}, Step {i+1}/{n_iterations}| Inputs {inputs.shape} | Labels {labels.shape}')\n",
        "\n",
        "# some famous datasets are available in torchvision.datasets\n",
        "# e.g. MNIST, Fashion-MNIST, CIFAR10, COCO\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=torchvision.transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=3,\n",
        "                                           shuffle=True)\n",
        "\n",
        "# look at one random sample\n",
        "dataiter = iter(train_loader)\n",
        "data = next(dataiter)\n",
        "inputs, targets = data\n",
        "print(inputs.shape, targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyzvZEfF_9kb",
        "outputId": "9d73523a-5bc7-4429-899b-b6f97d01dbe0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
            "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
            "        1.0650e+03]) tensor([1.])\n",
            "tensor([[1.4200e+01, 1.7600e+00, 2.4500e+00, 1.5200e+01, 1.1200e+02, 3.2700e+00,\n",
            "         3.3900e+00, 3.4000e-01, 1.9700e+00, 6.7500e+00, 1.0500e+00, 2.8500e+00,\n",
            "         1.4500e+03],\n",
            "        [1.3620e+01, 4.9500e+00, 2.3500e+00, 2.0000e+01, 9.2000e+01, 2.0000e+00,\n",
            "         8.0000e-01, 4.7000e-01, 1.0200e+00, 4.4000e+00, 9.1000e-01, 2.0500e+00,\n",
            "         5.5000e+02],\n",
            "        [1.3560e+01, 1.7100e+00, 2.3100e+00, 1.6200e+01, 1.1700e+02, 3.1500e+00,\n",
            "         3.2900e+00, 3.4000e-01, 2.3400e+00, 6.1300e+00, 9.5000e-01, 3.3800e+00,\n",
            "         7.9500e+02],\n",
            "        [1.4100e+01, 2.0200e+00, 2.4000e+00, 1.8800e+01, 1.0300e+02, 2.7500e+00,\n",
            "         2.9200e+00, 3.2000e-01, 2.3800e+00, 6.2000e+00, 1.0700e+00, 2.7500e+00,\n",
            "         1.0600e+03]]) tensor([[1.],\n",
            "        [3.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "178 45\n",
            "Epoch: 1/2, Step 5/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 10/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 15/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 20/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 25/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 30/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 35/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 40/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 1/2, Step 45/45| Inputs torch.Size([2, 13]) | Labels torch.Size([2, 1])\n",
            "Epoch: 2/2, Step 5/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 10/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 15/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 20/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 25/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 30/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 35/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 40/45| Inputs torch.Size([4, 13]) | Labels torch.Size([4, 1])\n",
            "Epoch: 2/2, Step 45/45| Inputs torch.Size([2, 13]) | Labels torch.Size([2, 1])\n",
            "torch.Size([3, 1, 28, 28]) torch.Size([3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transformers**"
      ],
      "metadata": {
        "id": "2k1QKnkdBFHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "\n",
        "    def __init__(self, transform=None):\n",
        "        xy = np.loadtxt('/content/wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
        "        self.n_samples = xy.shape[0]\n",
        "\n",
        "        # note that we do not convert to tensor here\n",
        "        self.x_data = xy[:, 1:]\n",
        "        self.y_data = xy[:, [0]]\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.x_data[index], self.y_data[index]\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "# Custom Transforms\n",
        "# implement __call__(self, sample)\n",
        "class ToTensor:\n",
        "    # Convert ndarrays to Tensors\n",
        "    def __call__(self, sample):\n",
        "        inputs, targets = sample\n",
        "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
        "\n",
        "class MulTransform:\n",
        "    # multiply inputs with a given factor\n",
        "    def __init__(self, factor):\n",
        "        self.factor = factor\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        inputs, targets = sample\n",
        "        inputs *= self.factor\n",
        "        return inputs, targets\n",
        "\n",
        "print('Without Transform')\n",
        "dataset = WineDataset()\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features, labels)\n",
        "\n",
        "print('\\nWith Tensor Transform')\n",
        "dataset = WineDataset(transform=ToTensor())\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features, labels)\n",
        "\n",
        "print('\\nWith Tensor and Multiplication Transform')\n",
        "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(4)])\n",
        "dataset = WineDataset(transform=composed)\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(type(features), type(labels))\n",
        "print(features, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2TTIufpBKnH",
        "outputId": "e8b08fb1-d2f9-4760-b220-0293754d58b5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without Transform\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
            " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03] [1.]\n",
            "\n",
            "With Tensor Transform\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
            "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
            "        1.0650e+03]) tensor([1.])\n",
            "\n",
            "With Tensor and Multiplication Transform\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "tensor([5.6920e+01, 6.8400e+00, 9.7200e+00, 6.2400e+01, 5.0800e+02, 1.1200e+01,\n",
            "        1.2240e+01, 1.1200e+00, 9.1600e+00, 2.2560e+01, 4.1600e+00, 1.5680e+01,\n",
            "        4.2600e+03]) tensor([1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Softmax and Crossentropy**"
      ],
      "metadata": {
        "id": "ku2NzggnBkCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "def softmax(x):\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "\n",
        "x = np.array([2.0, 1.0, 0.1])\n",
        "outputs = softmax(x)\n",
        "print('softmax numpy:', outputs)\n",
        "\n",
        "x = torch.tensor([2.0, 1.0, 0.1])\n",
        "outputs = torch.softmax(x, dim=0) # along values along first axis\n",
        "print('softmax torch:', outputs)\n",
        "\n",
        "# Cross entropy\n",
        "# Cross-entropy loss, or log loss, measures the performance of a classification model\n",
        "# whose output is a probability value between 0 and 1.\n",
        "# -> loss increases as the predicted probability diverges from the actual label\n",
        "def cross_entropy(actual, predicted):\n",
        "    EPS = 1e-15\n",
        "    predicted = np.clip(predicted, EPS, 1 - EPS)\n",
        "    loss = -np.sum(actual * np.log(predicted))\n",
        "    return loss # / float(predicted.shape[0])\n",
        "\n",
        "# y must be one hot encoded\n",
        "# if class 0: [1 0 0]\n",
        "# if class 1: [0 1 0]\n",
        "# if class 2: [0 0 1]\n",
        "Y = np.array([1, 0, 0])\n",
        "Y_pred_good = np.array([0.7, 0.2, 0.1])\n",
        "Y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
        "l1 = cross_entropy(Y, Y_pred_good)\n",
        "l2 = cross_entropy(Y, Y_pred_bad)\n",
        "print(f'Loss1 numpy: {l1:.4f}')\n",
        "print(f'Loss2 numpy: {l2:.4f}')\n",
        "\n",
        "# CrossEntropyLoss in PyTorch (applies Softmax)\n",
        "# nn.LogSoftmax + nn.NLLLoss\n",
        "# NLLLoss = negative log likelihood loss\n",
        "loss = nn.CrossEntropyLoss()\n",
        "# loss(input, target)\n",
        "\n",
        "# target is of size nSamples = 1\n",
        "# each element has class label: 0, 1, or 2\n",
        "# Y (=target) contains class labels, not one-hot\n",
        "Y = torch.tensor([0])\n",
        "\n",
        "# input is of size nSamples x nClasses = 1 x 3\n",
        "# y_pred (=input) must be raw, unnormalizes scores (logits) for each class, not softmax\n",
        "Y_pred_good = torch.tensor([[2.0, 1.0, 0.1]])\n",
        "Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3]])\n",
        "l1 = loss(Y_pred_good, Y)\n",
        "l2 = loss(Y_pred_bad, Y)\n",
        "\n",
        "print(f'PyTorch Loss1: {l1.item():.4f}')\n",
        "print(f'PyTorch Loss2: {l2.item():.4f}')\n",
        "\n",
        "# get predictions\n",
        "_, predictions1 = torch.max(Y_pred_good, 1)\n",
        "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
        "print(f'Actual class: {Y.item()}, Y_pred1: {predictions1.item()}, Y_pred2: {predictions2.item()}')\n",
        "\n",
        "# allows batch loss for multiple samples\n",
        "\n",
        "# target is of size nBatch = 3\n",
        "# each element has class label: 0, 1, or 2\n",
        "Y = torch.tensor([2, 0, 1])\n",
        "\n",
        "# input is of size nBatch x nClasses = 3 x 3\n",
        "# Y_pred are logits (not softmax)\n",
        "Y_pred_good = torch.tensor(\n",
        "    [[0.1, 0.2, 3.9], # predict class 2\n",
        "    [1.2, 0.1, 0.3], # predict class 0\n",
        "    [0.3, 2.2, 0.2]]) # predict class 1\n",
        "\n",
        "Y_pred_bad = torch.tensor(\n",
        "    [[0.9, 0.2, 0.1],\n",
        "    [0.1, 0.3, 1.5],\n",
        "    [1.2, 0.2, 0.5]])\n",
        "\n",
        "l1 = loss(Y_pred_good, Y)\n",
        "l2 = loss(Y_pred_bad, Y)\n",
        "print(f'Batch Loss1:  {l1.item():.4f}')\n",
        "print(f'Batch Loss2: {l2.item():.4f}')\n",
        "\n",
        "# get predictions\n",
        "_, predictions1 = torch.max(Y_pred_good, 1)\n",
        "_, predictions2 = torch.max(Y_pred_bad, 1)\n",
        "print(f'Actual class: {Y}, Y_pred1: {predictions1}, Y_pred2: {predictions2}')\n",
        "\n",
        "# Binary classification\n",
        "class NeuralNet1(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet1, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        # sigmoid at the end\n",
        "        y_pred = torch.sigmoid(out)\n",
        "        return y_pred\n",
        "\n",
        "model = NeuralNet1(input_size=28*28, hidden_size=5)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Multiclass problem\n",
        "class NeuralNet2(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet2, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        # no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet2(input_size=28*28, hidden_size=5, num_classes=3)\n",
        "criterion = nn.CrossEntropyLoss()  # (applies Softmax)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxb3MGITBZ32",
        "outputId": "b0a027e1-9dd3-4d9a-fe79-faf13617d4d2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "softmax numpy: [0.65900114 0.24243297 0.09856589]\n",
            "softmax torch: tensor([0.6590, 0.2424, 0.0986])\n",
            "Loss1 numpy: 0.3567\n",
            "Loss2 numpy: 2.3026\n",
            "PyTorch Loss1: 0.4170\n",
            "PyTorch Loss2: 1.8406\n",
            "Actual class: 0, Y_pred1: 0, Y_pred2: 1\n",
            "Batch Loss1:  0.2834\n",
            "Batch Loss2: 1.6418\n",
            "Actual class: tensor([2, 0, 1]), Y_pred1: tensor([2, 0, 1]), Y_pred2: tensor([0, 2, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Activation Function**"
      ],
      "metadata": {
        "id": "YFjpzdkkByj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# output = w*x + b\n",
        "# output = activation_function(output)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "x = torch.tensor([-1.0, 1.0, 2.0, 3.0])\n",
        "\n",
        "# sofmax\n",
        "output = torch.softmax(x, dim=0)\n",
        "print(output)\n",
        "sm = nn.Softmax(dim=0)\n",
        "output = sm(x)\n",
        "print(output)\n",
        "\n",
        "# sigmoid\n",
        "output = torch.sigmoid(x)\n",
        "print(output)\n",
        "s = nn.Sigmoid()\n",
        "output = s(x)\n",
        "print(output)\n",
        "\n",
        "#tanh\n",
        "output = torch.tanh(x)\n",
        "print(output)\n",
        "t = nn.Tanh()\n",
        "output = t(x)\n",
        "print(output)\n",
        "\n",
        "# relu\n",
        "output = torch.relu(x)\n",
        "print(output)\n",
        "relu = nn.ReLU()\n",
        "output = relu(x)\n",
        "print(output)\n",
        "\n",
        "# leaky relu\n",
        "output = F.leaky_relu(x)\n",
        "print(output)\n",
        "lrelu = nn.LeakyReLU()\n",
        "output = lrelu(x)\n",
        "print(output)\n",
        "\n",
        "#nn.ReLU() creates an nn.Module which you can add e.g. to an nn.Sequential model.\n",
        "#torch.relu on the other side is just the functional API call to the relu function,\n",
        "#so that you can add it e.g. in your forward method yourself.\n",
        "\n",
        "# option 1 (create nn modules)\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "# option 2 (use activation functions directly in forward pass)\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.relu(self.linear1(x))\n",
        "        out = torch.sigmoid(self.linear2(out))\n",
        "        return out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRt7II2gBxY1",
        "outputId": "3b798c86-fdd7-4406-d9b2-504003326a9b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0120, 0.0889, 0.2418, 0.6572])\n",
            "tensor([0.0120, 0.0889, 0.2418, 0.6572])\n",
            "tensor([0.2689, 0.7311, 0.8808, 0.9526])\n",
            "tensor([0.2689, 0.7311, 0.8808, 0.9526])\n",
            "tensor([-0.7616,  0.7616,  0.9640,  0.9951])\n",
            "tensor([-0.7616,  0.7616,  0.9640,  0.9951])\n",
            "tensor([0., 1., 2., 3.])\n",
            "tensor([0., 1., 2., 3.])\n",
            "tensor([-0.0100,  1.0000,  2.0000,  3.0000])\n",
            "tensor([-0.0100,  1.0000,  2.0000,  3.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot Activation**"
      ],
      "metadata": {
        "id": "KYWV7zinB7qP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# output = w*x + b\n",
        "# output = activation_function(output)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "x = torch.tensor([-1.0, 1.0, 2.0, 3.0])\n",
        "\n",
        "# sofmax\n",
        "output = torch.softmax(x, dim=0)\n",
        "print(output)\n",
        "sm = nn.Softmax(dim=0)\n",
        "output = sm(x)\n",
        "print(output)\n",
        "\n",
        "# sigmoid\n",
        "output = torch.sigmoid(x)\n",
        "print(output)\n",
        "s = nn.Sigmoid()\n",
        "output = s(x)\n",
        "print(output)\n",
        "\n",
        "#tanh\n",
        "output = torch.tanh(x)\n",
        "print(output)\n",
        "t = nn.Tanh()\n",
        "output = t(x)\n",
        "print(output)\n",
        "\n",
        "# relu\n",
        "output = torch.relu(x)\n",
        "print(output)\n",
        "relu = nn.ReLU()\n",
        "output = relu(x)\n",
        "print(output)\n",
        "\n",
        "# leaky relu\n",
        "output = F.leaky_relu(x)\n",
        "print(output)\n",
        "lrelu = nn.LeakyReLU()\n",
        "output = lrelu(x)\n",
        "print(output)\n",
        "\n",
        "#nn.ReLU() creates an nn.Module which you can add e.g. to an nn.Sequential model.\n",
        "#torch.relu on the other side is just the functional API call to the relu function,\n",
        "#so that you can add it e.g. in your forward method yourself.\n",
        "\n",
        "# option 1 (create nn modules)\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "# option 2 (use activation functions directly in forward pass)\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.relu(self.linear1(x))\n",
        "        out = torch.sigmoid(self.linear2(out))\n",
        "        return out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ei9IOrrlB_Z-",
        "outputId": "c9f24316-ba6c-4293-91d5-c3dec9efda14"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0120, 0.0889, 0.2418, 0.6572])\n",
            "tensor([0.0120, 0.0889, 0.2418, 0.6572])\n",
            "tensor([0.2689, 0.7311, 0.8808, 0.9526])\n",
            "tensor([0.2689, 0.7311, 0.8808, 0.9526])\n",
            "tensor([-0.7616,  0.7616,  0.9640,  0.9951])\n",
            "tensor([-0.7616,  0.7616,  0.9640,  0.9951])\n",
            "tensor([0., 1., 2., 3.])\n",
            "tensor([0., 1., 2., 3.])\n",
            "tensor([-0.0100,  1.0000,  2.0000,  3.0000])\n",
            "tensor([-0.0100,  1.0000,  2.0000,  3.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feed Forward**"
      ],
      "metadata": {
        "id": "vK2vvPS_CIqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "examples = iter(test_loader)\n",
        "example_data, example_targets = next(examples)\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(example_data[i][0], cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [100, 1, 28, 28]\n",
        "        # resized: [100, 784]\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "eKNuflTfCDSf",
        "outputId": "01bfbabe-a697-4ba2-d8a5-937df8da2431"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2], Step [100/600], Loss: 0.2966\n",
            "Epoch [1/2], Step [200/600], Loss: 0.2342\n",
            "Epoch [1/2], Step [300/600], Loss: 0.2188\n",
            "Epoch [1/2], Step [400/600], Loss: 0.3423\n",
            "Epoch [1/2], Step [500/600], Loss: 0.1430\n",
            "Epoch [1/2], Step [600/600], Loss: 0.2413\n",
            "Epoch [2/2], Step [100/600], Loss: 0.0524\n",
            "Epoch [2/2], Step [200/600], Loss: 0.1862\n",
            "Epoch [2/2], Step [300/600], Loss: 0.1235\n",
            "Epoch [2/2], Step [400/600], Loss: 0.0836\n",
            "Epoch [2/2], Step [500/600], Loss: 0.1799\n",
            "Epoch [2/2], Step [600/600], Loss: 0.0672\n",
            "Accuracy of the network on the 10000 test images: 96.9 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CMN"
      ],
      "metadata": {
        "id": "2NMUsbbyCQvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "num_epochs = 5\n",
        "batch_size = 4\n",
        "learning_rate = 0.001\n",
        "\n",
        "# dataset has PILImage images of range [0, 1].\n",
        "# We transform them to Tensors of normalized range [-1, 1]\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                         shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # -> n, 3, 32, 32\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # -> n, 16, 5, 5\n",
        "        x = x.view(-1, 16 * 5 * 5)            # -> n, 400\n",
        "        x = F.relu(self.fc1(x))               # -> n, 120\n",
        "        x = F.relu(self.fc2(x))               # -> n, 84\n",
        "        x = self.fc3(x)                       # -> n, 10\n",
        "        return x\n",
        "\n",
        "\n",
        "model = ConvNet().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n",
        "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 2000 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print('Finished Training')\n",
        "PATH = './cnn.pth'\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    n_class_correct = [0 for i in range(10)]\n",
        "    n_class_samples = [0 for i in range(10)]\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            label = labels[i]\n",
        "            pred = predicted[i]\n",
        "            if (label == pred):\n",
        "                n_class_correct[label] += 1\n",
        "            n_class_samples[label] += 1\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network: {acc} %')\n",
        "\n",
        "    for i in range(10):\n",
        "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
        "        print(f'Accuracy of {classes[i]}: {acc} %')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 996
        },
        "id": "Q8OHIls7CU_J",
        "outputId": "9daccfa0-ca27-4117-f5c4-9bdd38da5e13"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [2000/12500], Loss: 2.3125\n",
            "Epoch [1/5], Step [4000/12500], Loss: 2.2689\n",
            "Epoch [1/5], Step [6000/12500], Loss: 2.2662\n",
            "Epoch [1/5], Step [8000/12500], Loss: 2.2763\n",
            "Epoch [1/5], Step [10000/12500], Loss: 2.1535\n",
            "Epoch [1/5], Step [12000/12500], Loss: 2.2186\n",
            "Epoch [2/5], Step [2000/12500], Loss: 1.8195\n",
            "Epoch [2/5], Step [4000/12500], Loss: 1.9697\n",
            "Epoch [2/5], Step [6000/12500], Loss: 2.6568\n",
            "Epoch [2/5], Step [8000/12500], Loss: 1.8456\n",
            "Epoch [2/5], Step [10000/12500], Loss: 1.5981\n",
            "Epoch [2/5], Step [12000/12500], Loss: 1.5825\n",
            "Epoch [3/5], Step [2000/12500], Loss: 1.8782\n",
            "Epoch [3/5], Step [4000/12500], Loss: 1.1778\n",
            "Epoch [3/5], Step [6000/12500], Loss: 1.3843\n",
            "Epoch [3/5], Step [8000/12500], Loss: 2.0604\n",
            "Epoch [3/5], Step [10000/12500], Loss: 1.7972\n",
            "Epoch [3/5], Step [12000/12500], Loss: 1.4910\n",
            "Epoch [4/5], Step [2000/12500], Loss: 2.1553\n",
            "Epoch [4/5], Step [4000/12500], Loss: 1.6342\n",
            "Epoch [4/5], Step [6000/12500], Loss: 2.3402\n",
            "Epoch [4/5], Step [8000/12500], Loss: 1.3712\n",
            "Epoch [4/5], Step [10000/12500], Loss: 0.8620\n",
            "Epoch [4/5], Step [12000/12500], Loss: 1.4280\n",
            "Epoch [5/5], Step [2000/12500], Loss: 1.4206\n",
            "Epoch [5/5], Step [4000/12500], Loss: 1.5544\n",
            "Epoch [5/5], Step [6000/12500], Loss: 1.2095\n",
            "Epoch [5/5], Step [8000/12500], Loss: 1.8046\n",
            "Epoch [5/5], Step [10000/12500], Loss: 2.2629\n",
            "Epoch [5/5], Step [12000/12500], Loss: 1.4400\n",
            "Finished Training\n",
            "Accuracy of the network: 46.82 %\n",
            "Accuracy of plane: 56.9 %\n",
            "Accuracy of car: 79.9 %\n",
            "Accuracy of bird: 31.0 %\n",
            "Accuracy of cat: 17.4 %\n",
            "Accuracy of deer: 26.7 %\n",
            "Accuracy of dog: 58.4 %\n",
            "Accuracy of frog: 58.0 %\n",
            "Accuracy of horse: 45.3 %\n",
            "Accuracy of ship: 47.9 %\n",
            "Accuracy of truck: 46.7 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transfer Learning**"
      ],
      "metadata": {
        "id": "K2czFsphCYsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMEtMGgrZxQA",
        "outputId": "2657fafe-c661-4605-f616-97de11fa1e61"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "mean = np.array([0.5, 0.5, 0.5])\n",
        "std = np.array([0.25, 0.25, 0.25])\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = '/content/gdrive/MyDrive/daataset/hymenoptera_data'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
        "                                             shuffle=True, num_workers=0)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(class_names)\n",
        "\n",
        "\n",
        "def imshow(inp, title):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out, title=[class_names[x] for x in classes])\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        optimizer.zero_grad()\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "\n",
        "#### Finetuning the convnet ####\n",
        "# Load a pretrained model and reset final fully connected layer.\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "# Here the size of each output sample is set to 2.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "# StepLR Decays the learning rate of each parameter group by gamma every step_size epochs\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "# Learning rate scheduling should be applied after optimizers update\n",
        "# e.g., you should write your code this way:\n",
        "# for epoch in range(100):\n",
        "#     train(...)\n",
        "#     validate(...)\n",
        "#     scheduler.step()\n",
        "\n",
        "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=25)\n",
        "\n",
        "\n",
        "#### ConvNet as fixed feature extractor ####\n",
        "# Here, we need to freeze all the network except the final layer.\n",
        "# We need to set requires_grad == False to freeze the parameters so that the gradients are not computed in backward()\n",
        "model_conv = torchvision.models.resnet18(pretrained=True)\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "num_ftrs = model_conv.fc.in_features\n",
        "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as\n",
        "# opposed to before.\n",
        "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
        "\n",
        "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
        "                         exp_lr_scheduler, num_epochs=25)"
      ],
      "metadata": {
        "id": "ztyRDgFNCfTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensorboard**"
      ],
      "metadata": {
        "id": "eN34hsodC0Pw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "############## TENSORBOARD ########################\n",
        "import sys\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "# default `log_dir` is \"runs\" - we'll be more specific here\n",
        "writer = SummaryWriter('runs/mnist1')\n",
        "###################################################\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "num_epochs = 1\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "examples = iter(test_loader)\n",
        "example_data, example_targets = next(examples)\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(example_data[i][0], cmap='gray')\n",
        "#plt.show()\n",
        "\n",
        "############## TENSORBOARD ########################\n",
        "img_grid = torchvision.utils.make_grid(example_data)\n",
        "writer.add_image('mnist_images', img_grid)\n",
        "#writer.close()\n",
        "#sys.exit()\n",
        "###################################################\n",
        "\n",
        "# Fully connected neural network with one hidden layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        # no activation and no softmax at the end\n",
        "        return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "############## TENSORBOARD ########################\n",
        "writer.add_graph(model, example_data.reshape(-1, 28*28).to(device))\n",
        "#writer.close()\n",
        "#sys.exit()\n",
        "###################################################\n",
        "\n",
        "# Train the model\n",
        "running_loss = 0.0\n",
        "running_correct = 0\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # origin shape: [100, 1, 28, 28]\n",
        "        # resized: [100, 784]\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        running_correct += (predicted == labels).sum().item()\n",
        "        if (i+1) % 100 == 0:\n",
        "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
        "            ############## TENSORBOARD ########################\n",
        "            writer.add_scalar('training loss', running_loss / 100, epoch * n_total_steps + i)\n",
        "            running_accuracy = running_correct / 100 / predicted.size(0)\n",
        "            writer.add_scalar('accuracy', running_accuracy, epoch * n_total_steps + i)\n",
        "            running_correct = 0\n",
        "            running_loss = 0.0\n",
        "            ###################################################\n",
        "\n",
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "class_labels = []\n",
        "class_preds = []\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        values, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        class_probs_batch = [F.softmax(output, dim=0) for output in outputs]\n",
        "\n",
        "        class_preds.append(class_probs_batch)\n",
        "        class_labels.append(labels)\n",
        "\n",
        "    # 10000, 10, and 10000, 1\n",
        "    # stack concatenates tensors along a new dimension\n",
        "    # cat concatenates tensors in the given dimension\n",
        "    class_preds = torch.cat([torch.stack(batch) for batch in class_preds])\n",
        "    class_labels = torch.cat(class_labels)\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy of the network on the 10000 test images: {acc} %')\n",
        "\n",
        "    ############## TENSORBOARD ########################\n",
        "    classes = range(10)\n",
        "    for i in classes:\n",
        "        labels_i = class_labels == i\n",
        "        preds_i = class_preds[:, i]\n",
        "        writer.add_pr_curve(str(i), labels_i, preds_i, global_step=0)\n",
        "        writer.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "0bORBspcC6LA",
        "outputId": "6db95765-c73f-4282-dcf8-b30dc8ac68f9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Step [100/938], Loss: 0.4751\n",
            "Epoch [1/1], Step [200/938], Loss: 0.2441\n",
            "Epoch [1/1], Step [300/938], Loss: 0.4787\n",
            "Epoch [1/1], Step [400/938], Loss: 0.1164\n",
            "Epoch [1/1], Step [500/938], Loss: 0.2125\n",
            "Epoch [1/1], Step [600/938], Loss: 0.1249\n",
            "Epoch [1/1], Step [700/938], Loss: 0.0862\n",
            "Epoch [1/1], Step [800/938], Loss: 0.1087\n",
            "Epoch [1/1], Step [900/938], Loss: 0.1698\n",
            "Accuracy of the network on the 10000 test images: 96.48 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save and Load**"
      ],
      "metadata": {
        "id": "9gfIgmFqC7Bb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, n_input_features):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "\n",
        "model = Model(n_input_features=6)\n",
        "# train your model...\n",
        "\n",
        "####################save all ######################################\n",
        "for param in model.parameters():\n",
        "    print(param)\n",
        "\n",
        "# save and load entire model\n",
        "\n",
        "FILE = \"model.pth\"\n",
        "torch.save(model, FILE)\n",
        "\n",
        "loaded_model = torch.load(FILE)\n",
        "loaded_model.eval()\n",
        "\n",
        "for param in loaded_model.parameters():\n",
        "    print(param)\n",
        "\n",
        "\n",
        "############save only state dict #########################\n",
        "\n",
        "# save only state dict\n",
        "FILE = \"model.pth\"\n",
        "torch.save(model.state_dict(), FILE)\n",
        "\n",
        "print(model.state_dict())\n",
        "loaded_model = Model(n_input_features=6)\n",
        "loaded_model.load_state_dict(torch.load(FILE)) # it takes the loaded dictionary, not the path file itself\n",
        "loaded_model.eval()\n",
        "\n",
        "print(loaded_model.state_dict())\n",
        "\n",
        "\n",
        "###########load checkpoint#####################\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "checkpoint = {\n",
        "\"epoch\": 90,\n",
        "\"model_state\": model.state_dict(),\n",
        "\"optim_state\": optimizer.state_dict()\n",
        "}\n",
        "print(optimizer.state_dict())\n",
        "FILE = \"checkpoint.pth\"\n",
        "torch.save(checkpoint, FILE)\n",
        "\n",
        "model = Model(n_input_features=6)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0)\n",
        "\n",
        "checkpoint = torch.load(FILE)\n",
        "model.load_state_dict(checkpoint['model_state'])\n",
        "optimizer.load_state_dict(checkpoint['optim_state'])\n",
        "epoch = checkpoint['epoch']\n",
        "\n",
        "model.eval()\n",
        "# - or -\n",
        "# model.train()\n",
        "\n",
        "print(optimizer.state_dict())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSCQRJfJDBUi",
        "outputId": "f42a78fd-dfdc-4470-8c43-0da949b974c0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.4071, -0.0197, -0.2110, -0.1008, -0.1429,  0.3989]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.3223], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.4071, -0.0197, -0.2110, -0.1008, -0.1429,  0.3989]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.3223], requires_grad=True)\n",
            "OrderedDict([('linear.weight', tensor([[ 0.4071, -0.0197, -0.2110, -0.1008, -0.1429,  0.3989]])), ('linear.bias', tensor([0.3223]))])\n",
            "OrderedDict([('linear.weight', tensor([[ 0.4071, -0.0197, -0.2110, -0.1008, -0.1429,  0.3989]])), ('linear.bias', tensor([0.3223]))])\n",
            "{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1]}]}\n",
            "{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1]}]}\n"
          ]
        }
      ]
    }
  ]
}